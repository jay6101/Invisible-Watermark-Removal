# -*- coding: utf-8 -*-
"""Nov29_Postprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUMsozaWbhsXZCMuvAKl3ZQWxlKiMS65
"""

!pip install git+https://github.com/richzhang/PerceptualSimilarity

from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
from PIL import Image
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.utils import save_image
from diffusers import AutoencoderKL
import lpips
from skimage import color
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
import pandas as pd

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


DATA_ROOT = "/content/drive/MyDrive/400x400_paired_data"
FINETUNED_VAE_DIR = "/content/drive/MyDrive/vae_finetuning/models_new_improved"
REFINER_VAE_DIR = "stabilityai/sdxl-vae"
FINAL_OUT_DIR = "/content/drive/MyDrive/qpp_outputs"
RESULTS_CSV = "/content/drive/MyDrive/qpp_metrics.csv"

os.makedirs(FINAL_OUT_DIR, exist_ok=True)


TEST_TIME_STEPS = 2      # Paper doesn't specify exact number, but uses iterative optimization
TEST_TIME_LR = 1e-4       # Conservative learning rate for stability


def load_img(path):
    """Load image and convert to tensor in [0, 1]"""
    img = Image.open(path).convert("RGB")
    arr = np.array(img).astype(np.float32) / 255.0
    return torch.tensor(arr).permute(2, 0, 1).unsqueeze(0).to(DEVICE)

def to_m11(x):
    """Convert [0, 1] to [-1, 1]"""
    return x * 2 - 1

def to_01(x):
    """Convert [-1, 1] to [0, 1]"""
    return (x + 1) / 2


# SSIM IMPLEMENTATION (FOR LOSS COMPUTATION)
def gaussian(window_size, sigma):
    gauss = torch.Tensor([np.exp(-(x - window_size//2)**2 / float(2*sigma**2))
                          for x in range(window_size)])
    return gauss / gauss.sum()

def create_window(window_size, channel):
    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)
    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()
    return window

def compute_ssim(img1, img2, window_size=11, size_average=True):
    """
    Compute SSIM between two tensors in [-1, 1] range
    Returns SSIM value (higher is better, range [0, 1])
    """
    C1 = (0.01 * 2) ** 2
    C2 = (0.03 * 2) ** 2

    channel = img1.size(1)
    window = create_window(window_size, channel).to(img1.device).type_as(img1)

    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)
    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)

    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2

    sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq
    sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq
    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2

    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2)) / ((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))

    if size_average:
        return ssim_map.mean()
    else:
        return ssim_map.mean(1).mean(1).mean(1)


# METRICS FOR EVALUATION
lpips_model = lpips.LPIPS(net='alex').to(DEVICE)

def metric_psnr(a, b):
    """PSNR between two tensors in [-1, 1]"""
    a_np = to_01(a).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    b_np = to_01(b).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    return peak_signal_noise_ratio(a_np, b_np, data_range=1.0)

def metric_ssim(a, b):
    """SSIM between two tensors in [-1, 1]"""
    a_np = to_01(a).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    b_np = to_01(b).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    return structural_similarity(a_np, b_np, channel_axis=2, data_range=1.0)

def metric_lpips(a, b):
    """LPIPS between two tensors in [-1, 1]"""
    return lpips_model(a, b).mean().item()

print("Loading finetuned VAE (for initial reconstruction)...")
vae_finetuned = AutoencoderKL.from_pretrained(
    FINETUNED_VAE_DIR,
    torch_dtype=torch.float32
).to(DEVICE)
vae_finetuned.eval()

print("Loading SDXL Refiner VAE (for test-time optimization)...")
# Important: Load a FRESH instance for test-time optimization
vae_refiner = AutoencoderKL.from_pretrained(
    REFINER_VAE_DIR,
    torch_dtype=torch.float32
).to(DEVICE)

# L_total = ||D(E(x_r)) - x_w||^2 + L_LPIPS + 0.5(1 - SSIM)
def test_time_optimize(x_r_init, x_w, steps=TEST_TIME_STEPS, lr=TEST_TIME_LR):
    """
    Performs test-time VAE optimization per image.

    Args:
        x_r_init: Initial reconstruction from finetuned VAE [1,3,H,W] in [-1,1]
        x_w: Original watermarked image [1,3,H,W] in [-1,1]
        steps: Number of optimization steps (T in Algorithm 2)
        lr: Learning rate (η in Algorithm 2)

    Returns:
        x_opt: Optimized reconstruction [1,3,H,W] in [-1,1]
    """
    vae_refiner_copy = AutoencoderKL.from_pretrained(
        REFINER_VAE_DIR,
        torch_dtype=torch.float32
    ).to(DEVICE)
    vae_refiner_copy.train()

    # Create optimizer for refiner VAE parameters
    optimizer = torch.optim.Adam(vae_refiner_copy.parameters(), lr=lr)

    x_r = x_r_init.clone().detach()

    print(f"  Test-time optimization: {steps} steps...")
    for t in range(steps):
        optimizer.zero_grad()

        # Encode and decode through refiner VAE
        posterior = vae_refiner_copy.encode(x_r).latent_dist
        z = posterior.mean
        x_recon = vae_refiner_copy.decode(z).sample

        # Paper Equation 2: MSE + LPIPS + 0.5*(1 - SSIM)
        mse_loss = F.mse_loss(x_recon, x_w)
        lpips_loss = lpips_model(x_recon, x_w).mean()
        ssim_val = compute_ssim(x_recon, x_w)
        ssim_loss = 0.5 * (1 - ssim_val)

        total_loss = mse_loss + lpips_loss + ssim_loss

        # Backprop and update
        total_loss.backward()
        optimizer.step()

        # Update x_r for next iteration
        with torch.no_grad():
            x_r = x_recon.clone()

        if (t + 1) % 10 == 0:
            print(f"    Step [{t+1}/{steps}] MSE={mse_loss.item():.4f} "
                  f"LPIPS={lpips_loss.item():.4f} SSIM_Loss={ssim_loss.item():.4f}")

    # Final forward pass to get optimized output
    vae_refiner_copy.eval()
    with torch.no_grad():
        posterior = vae_refiner_copy.encode(x_r).latent_dist
        z = posterior.mean
        x_opt = vae_refiner_copy.decode(z).sample

    del vae_refiner_copy  # Free memory
    torch.cuda.empty_cache()

    return x_opt

# COLOR + CONTRAST TRANSFER

def color_contrast_transfer(x_opt, x_w):
    """
    Performs color and contrast transfer in CIELAB space.

    Paper steps:
    1. Convert x_opt and x_w to CIELAB
    2. Color transfer: Use L from x_opt, a,b from x_w
    3. Contrast transfer: L_final = (σ_w/σ_c)*(L_c - μ_c) + μ_w
    4. Combine: [L_final, a_w, b_w] and convert back to RGB

    Args:
        x_opt: Optimized image [1,3,H,W] in [-1,1]
        x_w: Original watermarked image [1,3,H,W] in [-1,1]

    Returns:
        x_final: Final image [1,3,H,W] in [-1,1]
    """
    print("  Color and contrast transfer (CIELAB)...")

    # Convert to [0,1] and numpy for skimage
    opt_np = to_01(x_opt).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    w_np = to_01(x_w).squeeze().detach().cpu().numpy().transpose(1, 2, 0)

    # Convert to CIELAB
    lab_opt = color.rgb2lab(opt_np)
    lab_w = color.rgb2lab(w_np)

    # Extract channels: L (luminance), a,b (chrominance)
    L_opt = lab_opt[:, :, 0]
    a_opt = lab_opt[:, :, 1]
    b_opt = lab_opt[:, :, 2]

    L_w = lab_w[:, :, 0]
    a_w = lab_w[:, :, 1]
    b_w = lab_w[:, :, 2]

    # Step 1: Color transfer - preserve L_opt, adopt a_w, b_w
    # This creates intermediate x_c in the paper

    # Step 2: Contrast transfer on luminance
    mu_c = L_opt.mean()
    sigma_c = L_opt.std()
    mu_w = L_w.mean()
    sigma_w = L_w.std()

    # Avoid division by zero
    if sigma_c < 1e-6:
        sigma_c = 1e-6

    # Paper formula: L_final = (σ_w/σ_c)*(L_c - μ_c) + μ_w
    L_final = (sigma_w / sigma_c) * (L_opt - mu_c) + mu_w

    # Combine adjusted luminance with watermarked chrominance
    lab_final = np.stack([L_final, a_w, b_w], axis=2)

    # Convert back to RGB
    rgb_final = color.lab2rgb(lab_final)

    # Convert back to tensor in [-1, 1]
    x_final = torch.tensor(rgb_final).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE)
    x_final = to_m11(x_final)

    return x_final


# ---------------------------------------------------------
# MAIN PROCESSING LOOP
# ---------------------------------------------------------
records = []

all_folders = sorted([d for d in os.listdir(DATA_ROOT) if not d.startswith(".")])
print(f"\nProcessing {len(all_folders)} folders...\n")

for folder in tqdm(all_folders, desc="Post-Processing"):
    fpath = os.path.join(DATA_ROOT, folder)
    if not os.path.isdir(fpath):
        continue

    xw_path = os.path.join(fpath, f"{folder}_hidden.png")
    xi_path = os.path.join(fpath, f"{folder}_hidden_inv.png")

    if not (os.path.exists(xw_path) and os.path.exists(xi_path)):
        continue

    print(f"\n[{folder}]")

    # Load images and convert to [-1, 1]
    x_w = to_m11(load_img(xw_path))
    x_i = to_m11(load_img(xi_path))

    # STEP 1: Initial reconstruction (finetuned VAE)

    print("  Step 1: Initial reconstruction (finetuned VAE)...")
    with torch.no_grad():
        posterior = vae_finetuned.encode(x_w).latent_dist
        z = posterior.mean
        x_r_init = vae_finetuned.decode(z).sample

    # STEP 2: Test-Time Optimization (refiner VAE)
    print("  Step 2: Test-time optimization (refiner VAE)...")
    x_opt = test_time_optimize(x_r_init, x_w, steps=TEST_TIME_STEPS, lr=TEST_TIME_LR)

    # STEP 3: Color + Contrast Transfer (CIELAB)
    x_final = color_contrast_transfer(x_opt, x_w)

    # Save final output
    save_path = os.path.join(FINAL_OUT_DIR, f"{folder}_final.png")
    save_image(to_01(x_final), save_path)
    print(f"  Saved: {save_path}")

    # Compute metrics vs. ground truth (inverse watermark image)
    psnr_val = metric_psnr(x_final, x_i)
    ssim_val = metric_ssim(x_final, x_i)
    lpips_val = metric_lpips(x_final, x_i)

    print(f"  Metrics vs GT: PSNR={psnr_val:.2f} SSIM={ssim_val:.4f} LPIPS={lpips_val:.4f}")

    records.append({
        "id": folder,
        "psnr": psnr_val,
        "ssim": ssim_val,
        "lpips": lpips_val,
    })

df = pd.DataFrame(records)
df.to_csv(RESULTS_CSV, index=False)

print("\n" + "="*60)
print("PROCESSING COMPLETE")
print("="*60)
print(f"\nResults saved to: {RESULTS_CSV}")
print(f"Output images saved to: {FINAL_OUT_DIR}")

print("\n" + "="*60)
print("AGGREGATED METRICS (Table 4 style)")
print("="*60)
print(f"PSNR: {df['psnr'].mean():.3f} dB")
print(f"SSIM: {df['ssim'].mean():.4f}")
print(f"LPIPS: {df['lpips'].mean():.4f}")

