# -*- coding: utf-8 -*-
"""Testing_StegaStamp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j02imhpB95tXKVx9k13Ss-hBCsluVIqj
"""

from google.colab import drive
drive.mount('/content/drive')

# -*- coding: utf-8 -*-
"""
VAE Evaluation with StegaStamp Decoding
Evaluates watermark removal by decoding 100-bit messages
"""

import os
import numpy as np
from PIL import Image, ImageOps
from tqdm import tqdm
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from diffusers import AutoencoderKL
import tensorflow as tf
import pandas as pd
from termcolor import colored

# Suppress TF warnings
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
tf.compat.v1.disable_eager_execution()

# ============================================================================
# CONFIGURATION - UPDATE THESE PATHS
# ============================================================================
DATA_ROOT = "/content/drive/MyDrive/400x400_test_paired_data"
FINETUNED_VAE_DIR = "/content/drive/MyDrive/vae_finetuning/models_new_improved"  # Your finetuned VAE
TF_MODEL_DIR = "/content/drive/MyDrive/stegastamp_pretrained"  # StegaStamp decoder
VAE_OUT_DIR = "/content/drive/MyDrive/vae_finetuning/vae_output_nov30"  # Where to save VAE outputs


os.makedirs(VAE_OUT_DIR, exist_ok=True)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
BATCH_SIZE = 16
DTYPE = torch.float32


# ============================================================================
# DATASET FOR INFERENCE
# ============================================================================
class InferenceDataset(Dataset):
    def __init__(self, root, transform=None):
        self.root = root
        self.tf = transform
        all_folders = sorted([d for d in os.listdir(root) if not d.startswith(".")])
        self.items = []

        for folder in all_folders:
            fpath = os.path.join(root, folder)
            if not os.path.isdir(fpath):
                continue

            xw_path = os.path.join(fpath, f"{folder}_hidden.png")
            secret_path = os.path.join(fpath, f"{folder}_secret.txt")

            if os.path.exists(xw_path) and os.path.exists(secret_path):
                self.items.append({
                    "id": folder,
                    "hidden": xw_path,
                    "secret": secret_path
                })

        print(f"Loaded {len(self.items)} items for evaluation.")

    def __len__(self):
        return len(self.items)

    def __getitem__(self, idx):
        item = self.items[idx]
        xw = Image.open(item["hidden"]).convert("RGB")
        if self.tf:
            xw = self.tf(xw)
        return xw, item["id"]

    def get_metadata(self):
        return self.items


# ============================================================================
# LOAD FINETUNED VAE
# ============================================================================
print(colored("Loading finetuned VAE...", "yellow"))
vae = AutoencoderKL.from_pretrained(
    FINETUNED_VAE_DIR,
    torch_dtype=DTYPE
).to(DEVICE)
vae.enable_slicing()
vae.enable_tiling()
vae = vae.to(memory_format=torch.channels_last)
vae.eval()
print(colored("✅ VAE loaded successfully", "green"))


# ============================================================================
# VAE RECONSTRUCTION INFERENCE
# ============================================================================
transform = transforms.Compose([
    transforms.Resize((400, 400)),
    transforms.ToTensor(),  # [0, 1]
])

dataset = InferenceDataset(DATA_ROOT, transform)
loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False,
                   num_workers=4, pin_memory=True)
metadata = dataset.get_metadata()

def denorm(x):
    """Convert [-1, 1] to [0, 1]"""
    return ((x + 1) / 2).clamp(0, 1)

print(colored("\nRunning VAE reconstruction inference...", "cyan"))

with torch.no_grad():
    for xw_batch, ids_batch in tqdm(loader, desc="VAE Reconstruction"):
        xw_batch = xw_batch.to(DEVICE, non_blocking=True)
        xw_batch = xw_batch.to(memory_format=torch.channels_last)

        # Scale to [-1, 1] (matching your training)
        xw_batch = xw_batch * 2 - 1

        # Encode and decode
        posterior = vae.encode(xw_batch).latent_dist
        z = posterior.mean  # Use mean for deterministic reconstruction
        x_recon = vae.decode(z).sample

        # Denormalize to [0, 1]
        x_recon = denorm(x_recon)

        # Save reconstructed images
        for i in range(x_recon.size(0)):
            img_tensor = x_recon[i].cpu().float()
            img_id = ids_batch[i]
            save_path = os.path.join(VAE_OUT_DIR, f"{img_id}_vae.png")
            img_pil = transforms.ToPILImage()(img_tensor)
            img_pil.save(save_path, 'PNG')

print(colored(f"✅ VAE reconstruction complete. Saved to {VAE_OUT_DIR}", "green"))

!pip install git+https://github.com/richzhang/PerceptualSimilarity

import os
import numpy as np
from PIL import Image
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.utils import save_image
from diffusers import AutoencoderKL
import lpips
from skimage import color
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
import pandas as pd

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

DATA_ROOT = "/content/drive/MyDrive/400x400_test_paired_data"
FINETUNED_VAE_DIR = "/content/drive/MyDrive/vae_finetuning/models_new_improved"
REFINER_VAE_DIR = "stabilityai/sdxl-vae"
FINAL_OUT_DIR = "/content/drive/MyDrive/qpp_outputs_test_nov30"
RESULTS_CSV = "/content/drive/MyDrive/qpp_metrics_test_nov30.csv"

os.makedirs(FINAL_OUT_DIR, exist_ok=True)
=
TEST_TIME_STEPS = 10
TEST_TIME_LR = 1e-4

def load_img(path):
    """Load image and convert to tensor in [0, 1]"""
    img = Image.open(path).convert("RGB")
    arr = np.array(img).astype(np.float32) / 255.0
    return torch.tensor(arr).permute(2, 0, 1).unsqueeze(0).to(DEVICE)

def to_m11(x):
    """Convert [0, 1] to [-1, 1]"""
    return x * 2 - 1

def to_01(x):
    """Convert [-1, 1] to [0, 1]"""
    return (x + 1) / 2


# SSIM IMPLEMENTATION (FOR LOSS COMPUTATION)
def gaussian(window_size, sigma):
    gauss = torch.Tensor([np.exp(-(x - window_size//2)**2 / float(2*sigma**2))
                          for x in range(window_size)])
    return gauss / gauss.sum()

def create_window(window_size, channel):
    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)
    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
    window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()
    return window

def compute_ssim(img1, img2, window_size=11, size_average=True):
    """
    Compute SSIM between two tensors in [-1, 1] range
    Returns SSIM value (higher is better, range [0, 1])
    """
    C1 = (0.01 * 2) ** 2
    C2 = (0.03 * 2) ** 2

    channel = img1.size(1)
    window = create_window(window_size, channel).to(img1.device).type_as(img1)

    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)
    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)

    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2

    sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq
    sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq
    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2

    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2)) / ((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))

    if size_average:
        return ssim_map.mean()
    else:
        return ssim_map.mean(1).mean(1).mean(1)


# METRICS FOR EVALUATION
lpips_model = lpips.LPIPS(net='alex').to(DEVICE)

def metric_psnr(a, b):
    """PSNR between two tensors in [-1, 1]"""
    a_np = to_01(a).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    b_np = to_01(b).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    return peak_signal_noise_ratio(a_np, b_np, data_range=1.0)

def metric_ssim(a, b):
    """SSIM between two tensors in [-1, 1]"""
    a_np = to_01(a).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    b_np = to_01(b).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    return structural_similarity(a_np, b_np, channel_axis=2, data_range=1.0)

def metric_lpips(a, b):
    """LPIPS between two tensors in [-1, 1]"""
    return lpips_model(a, b).mean().item()

print("Loading finetuned VAE (for initial reconstruction)...")
vae_finetuned = AutoencoderKL.from_pretrained(
    FINETUNED_VAE_DIR,
    torch_dtype=torch.float32
).to(DEVICE)
vae_finetuned.eval()

print("Loading SDXL Refiner VAE (for test-time optimization)...")
vae_refiner = AutoencoderKL.from_pretrained(
    REFINER_VAE_DIR,
    torch_dtype=torch.float32
).to(DEVICE)


# L_total = ||D(E(x_r)) - x_w||^2 + L_LPIPS + 0.5(1 - SSIM)
def test_time_optimize(x_r_init, x_w, steps=TEST_TIME_STEPS, lr=TEST_TIME_LR):
    """
    Performs test-time VAE optimization per image.

    Args:
        x_r_init: Initial reconstruction from finetuned VAE [1,3,H,W] in [-1,1]
        x_w: Original watermarked image [1,3,H,W] in [-1,1]
        steps: Number of optimization steps (T in Algorithm 2)
        lr: Learning rate (η in Algorithm 2)

    Returns:
        x_opt: Optimized reconstruction [1,3,H,W] in [-1,1]
    """
    # Reset refiner VAE to pretrained state for each image
    # This ensures we start fresh for each test-time optimization
    vae_refiner_copy = AutoencoderKL.from_pretrained(
        REFINER_VAE_DIR,
        torch_dtype=torch.float32
    ).to(DEVICE)
    vae_refiner_copy.train()

    # Create optimizer for refiner VAE parameters
    optimizer = torch.optim.Adam(vae_refiner_copy.parameters(), lr=lr)

    x_r = x_r_init.clone().detach()

    print(f"  Test-time optimization: {steps} steps...")
    for t in range(steps):
        optimizer.zero_grad()

        # Encode and decode through refiner VAE
        posterior = vae_refiner_copy.encode(x_r).latent_dist
        z = posterior.mean
        x_recon = vae_refiner_copy.decode(z).sample

        # Paper Equation 2: MSE + LPIPS + 0.5*(1 - SSIM)
        mse_loss = F.mse_loss(x_recon, x_w)
        lpips_loss = lpips_model(x_recon, x_w).mean()
        ssim_val = compute_ssim(x_recon, x_w)
        ssim_loss = 0.5 * (1 - ssim_val)

        total_loss = mse_loss + lpips_loss + ssim_loss

        # Backprop and update
        total_loss.backward()
        optimizer.step()

        # Update x_r for next iteration
        with torch.no_grad():
            x_r = x_recon.clone()

        if (t + 1) % 10 == 0:
            print(f"    Step [{t+1}/{steps}] MSE={mse_loss.item():.4f} "
                  f"LPIPS={lpips_loss.item():.4f} SSIM_Loss={ssim_loss.item():.4f}")

    # Final forward pass to get optimized output
    vae_refiner_copy.eval()
    with torch.no_grad():
        posterior = vae_refiner_copy.encode(x_r).latent_dist
        z = posterior.mean
        x_opt = vae_refiner_copy.decode(z).sample

    del vae_refiner_copy  # Free memory
    torch.cuda.empty_cache()

    return x_opt


# COLOR + CONTRAST TRANSFER
def color_contrast_transfer(x_opt, x_w):
    """
    Performs color and contrast transfer in CIELAB space.

    Paper steps:
    1. Convert x_opt and x_w to CIELAB
    2. Color transfer: Use L from x_opt, a,b from x_w
    3. Contrast transfer: L_final = (σ_w/σ_c)*(L_c - μ_c) + μ_w
    4. Combine: [L_final, a_w, b_w] and convert back to RGB

    Args:
        x_opt: Optimized image [1,3,H,W] in [-1,1]
        x_w: Original watermarked image [1,3,H,W] in [-1,1]

    Returns:
        x_final: Final image [1,3,H,W] in [-1,1]
    """
    print("  Color and contrast transfer (CIELAB)...")

    # Convert to [0,1] and numpy for skimage
    opt_np = to_01(x_opt).squeeze().detach().cpu().numpy().transpose(1, 2, 0)
    w_np = to_01(x_w).squeeze().detach().cpu().numpy().transpose(1, 2, 0)

    # Convert to CIELAB
    lab_opt = color.rgb2lab(opt_np)
    lab_w = color.rgb2lab(w_np)

    # Extract channels: L (luminance), a,b (chrominance)
    L_opt = lab_opt[:, :, 0]
    a_opt = lab_opt[:, :, 1]
    b_opt = lab_opt[:, :, 2]

    L_w = lab_w[:, :, 0]
    a_w = lab_w[:, :, 1]
    b_w = lab_w[:, :, 2]

    # Step 1: Color transfer - preserve L_opt, adopt a_w, b_w
    # This creates intermediate x_c in the paper

    # Step 2: Contrast transfer on luminance
    mu_c = L_opt.mean()
    sigma_c = L_opt.std()
    mu_w = L_w.mean()
    sigma_w = L_w.std()

    # Avoid division by zero
    if sigma_c < 1e-6:
        sigma_c = 1e-6

    # Paper formula: L_final = (σ_w/σ_c)*(L_c - μ_c) + μ_w
    L_final = (sigma_w / sigma_c) * (L_opt - mu_c) + mu_w

    # Combine adjusted luminance with watermarked chrominance
    lab_final = np.stack([L_final, a_w, b_w], axis=2)

    # Convert back to RGB
    rgb_final = color.lab2rgb(lab_final)

    # Convert back to tensor in [-1, 1]
    x_final = torch.tensor(rgb_final).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE)
    x_final = to_m11(x_final)

    return x_final


# ---------------------------------------------------------
# MAIN PROCESSING LOOP
# ---------------------------------------------------------
records = []

all_folders = sorted([d for d in os.listdir(DATA_ROOT) if not d.startswith(".")])
print(f"\nProcessing {len(all_folders)} folders...\n")

for folder in tqdm(all_folders, desc="Post-Processing"):
    fpath = os.path.join(DATA_ROOT, folder)
    if not os.path.isdir(fpath):
        continue

    xw_path = os.path.join(fpath, f"{folder}_hidden.png")
    xi_path = os.path.join(fpath, f"{folder}_hidden_inv.png")

    if not (os.path.exists(xw_path) and os.path.exists(xi_path)):
        continue

    print(f"\n[{folder}]")

    # Load images and convert to [-1, 1]
    x_w = to_m11(load_img(xw_path))
    x_i = to_m11(load_img(xi_path))

    # STEP 1: Initial reconstruction (finetuned VAE)
    print("  Step 1: Initial reconstruction (finetuned VAE)...")
    with torch.no_grad():
        posterior = vae_finetuned.encode(x_w).latent_dist
        z = posterior.mean
        x_r_init = vae_finetuned.decode(z).sample

    # STEP 2: Test-Time Optimization (refiner VAE)
    print("  Step 2: Test-time optimization (refiner VAE)...")
    x_opt = test_time_optimize(x_r_init, x_w, steps=TEST_TIME_STEPS, lr=TEST_TIME_LR)

    # STEP 3: Color + Contrast Transfer (CIELAB)
    x_final = color_contrast_transfer(x_opt, x_w)

    # Save final output
    save_path = os.path.join(FINAL_OUT_DIR, f"{folder}_final.png")
    save_image(to_01(x_final), save_path)
    print(f"  Saved: {save_path}")

    # Compute metrics vs. ground truth (inverse watermark image)
    psnr_val = metric_psnr(x_final, x_i)
    ssim_val = metric_ssim(x_final, x_i)
    lpips_val = metric_lpips(x_final, x_i)

    print(f"  Metrics vs GT: PSNR={psnr_val:.2f} SSIM={ssim_val:.4f} LPIPS={lpips_val:.4f}")

    records.append({
        "id": folder,
        "psnr": psnr_val,
        "ssim": ssim_val,
        "lpips": lpips_val,
    })

df = pd.DataFrame(records)
df.to_csv(RESULTS_CSV, index=False)

print("\n" + "="*60)
print("PROCESSING COMPLETE")
print("="*60)
print(f"\nResults saved to: {RESULTS_CSV}")
print(f"Output images saved to: {FINAL_OUT_DIR}")

print("\n" + "="*60)
print("AGGREGATED METRICS (Table 4 style)")
print("="*60)
print(f"PSNR: {df['psnr'].mean():.3f} dB")
print(f"SSIM: {df['ssim'].mean():.4f}")
print(f"LPIPS: {df['lpips'].mean():.4f}")

"""Finding the Hamming distances

Hamming between watermarked and reconstructions
"""

# -*- coding: utf-8 -*-
"""
QPP Attack Evaluation Script (Self-Decoded Control)
Finalized version using nested original data structure and flat attacked data structure.
Compares decoded output of original images with decoded output of attacked images
via Hamming Distance, saving the results to a single CSV.
"""

import os
import numpy as np
import pandas as pd
from PIL import Image, ImageOps
from tqdm import tqdm
import tensorflow as tf
from termcolor import colored

# Suppress TF warnings and disable eager execution
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
tf.compat.v1.disable_eager_execution()

# Path to the nested folders containing image data (e.g., /.../000000/000000_hidden.png)
ORIGINAL_DATA_ROOT = "/content/drive/MyDrive/400x400_test_paired_data"
# Path to the single, flat folder containing all QPP output images (e.g., /.../qpp_outputs/000000_final.png)
QPP_OUTPUT_ROOT = "/content/drive/MyDrive/vae_finetuning/vae_output_nov30"
# Path to the StegaStamp TensorFlow decoder model
TF_MODEL_DIR_ROOT = "/content/drive/MyDrive/stegastamp_pretrained"
# Output directory and final CSV file path
EVAL_CSV_DIR = "/content/drive/MyDrive/hamm_bet_test_original_reconstruction"
FINAL_CSV_PATH = os.path.join(EVAL_CSV_DIR, "hamm_bet_qpp_initial.csv")

# Ensure the output directory exists
os.makedirs(EVAL_CSV_DIR, exist_ok=True)

# ============================================================================
# DECODER UTILITY FUNCTIONS
# ============================================================================

def find_model_path(root_path):
    """Checks the root and common subdirectories for the SavedModel files."""
    if os.path.exists(os.path.join(root_path, "saved_model.pb")):
        return root_path
    for subdir in ['1', 'saved_model']:
        test_path = os.path.join(root_path, subdir)
        if os.path.exists(os.path.join(test_path, "saved_model.pb")):
            return test_path
    return root_path # Return root if all checks fail

def load_decoder_handles(model_dir):
    """Load StegaStamp TensorFlow decoder model"""
    g = tf.Graph()
    sess = tf.compat.v1.Session(graph=g)
    meta = tf.compat.v1.saved_model.loader.load(sess, [tf.saved_model.SERVING], model_dir)
    sig = meta.signature_def["serving_default"]
    inp_image = g.get_tensor_by_name(sig.inputs["image"].name)
    inp_secret = g.get_tensor_by_name(sig.inputs["secret"].name)
    out_bits = g.get_tensor_by_name(sig.outputs["decoded"].name)
    return sess, {"image": inp_image, "secret": inp_secret}, out_bits

def preprocess_image_for_decoder(path):
    """Preprocess image for StegaStamp decoder: 400x400, RGB, [0,1]"""
    img = Image.open(path).convert("RGB")
    img = ImageOps.fit(img, (400, 400))
    arr = np.asarray(img).astype(np.float32) / 255.0
    return arr

def decode_bits(sess, inputs_dict, out_tensor, img_path):
    """Decode 100-bit message from image using StegaStamp decoder"""
    if not os.path.isfile(img_path): return None
    img_arr = preprocess_image_for_decoder(img_path)
    dummy_secret = np.zeros((1, 100), dtype=np.float32)
    feed_dict = {
        inputs_dict["image"]: img_arr[np.newaxis, ...],
        inputs_dict["secret"]: dummy_secret
    }
    pred_bits = sess.run(out_tensor, feed_dict=feed_dict)
    pred_bits = np.squeeze(pred_bits).astype(np.int64)
    return pred_bits if pred_bits.size == 100 else None

def compute_hamming(pred_bits, control_bits):
    """Compute Hamming distance (number of differing bits)"""
    if pred_bits is None or control_bits is None: return None
    L = min(len(pred_bits), len(control_bits))
    hamming_dist = int(np.sum(pred_bits[:L] != control_bits[:L]))
    return hamming_dist

# ============================================================================
# MAIN EVALUATION
# ============================================================================

# --- Load StegaStamp Decoder ---
# Attempt to handle potential nested folder structure for robust loading
TF_MODEL_DIR = find_model_path(TF_MODEL_DIR_ROOT)
print(colored(f"Attempting to load StegaStamp decoder from: {TF_MODEL_DIR}", "yellow"))

try:
    sess, inputs_dict, out_bits = load_decoder_handles(TF_MODEL_DIR)
    print(colored("✅ StegaStamp decoder loaded successfully", "green"))
except Exception as e:
    # If this fails, we cannot proceed, but since you said it works, this is a safeguard.
    print(colored(f"❌ Critical Error: Failed to load decoder model. If this persists, verify the contents of your model folder.", "red"))
    exit(1)

# --- Pass 1: Establish Control Keys (P_control) from Nested Folders ---
control_keys = {}
print(colored("\nStarting Pass 1: Decoding Control Keys from Original Watermarked Images...", "yellow"))

# Identify all image IDs by looking at the subfolders in the original data root
all_folders = [d for d in os.listdir(ORIGINAL_DATA_ROOT) if os.path.isdir(os.path.join(ORIGINAL_DATA_ROOT, d)) and not d.startswith('.')]

for image_id in tqdm(all_folders, desc="Pass 1: Decoding Control Keys"):
    # Path format: DATA_ROOT/000000/000000_hidden.png
    original_path = os.path.join(ORIGINAL_DATA_ROOT, image_id, f"{image_id}_hidden.png")

    if os.path.exists(original_path):
        p_control = decode_bits(sess, inputs_dict, out_bits, original_path)

        if p_control is not None:
            control_keys[image_id] = p_control

print(colored(f"✅ Control keys established for {len(control_keys)} images.", "green"))

# --- Pass 2: Evaluate Attacked Images (P_attack) against Control Keys ---
print(colored("\nStarting Pass 2: Evaluating Attacked Images...", "cyan"))

final_records = []
qpp_images = [f for f in os.listdir(QPP_OUTPUT_ROOT) if f.endswith(".png") or f.endswith(".jpg")]
processed_images = 0

for img_file in tqdm(qpp_images, desc="Pass 2: Decoding QPP Outputs"):
    try:
        # Extract image_id (e.g., '000000' from '000000_final.png')
        image_id = img_file.split('_')[0]
    except IndexError:
        continue

    # Get the control key
    p_control = control_keys.get(image_id)
    if p_control is None:
        continue

    qpp_img_path = os.path.join(QPP_OUTPUT_ROOT, img_file)

    # Decode the attacked image (P_attack)
    p_attack = decode_bits(sess, inputs_dict, out_bits, qpp_img_path)

    # Compute Hamming distance: Hamming(P_attack, P_control)
    ham_sd = compute_hamming(p_attack, p_control)

    if ham_sd is not None:
         final_records.append({
            "image_id": image_id,
            "attack_type": "QPP_Self_Decoded",
            "hamming_distance": ham_sd,
        })
         processed_images += 1

# Save the final CSV
final_df = pd.DataFrame(final_records)
final_df.to_csv(FINAL_CSV_PATH, index=False)

# --- Final Console Output (No plots, just required summary) ---
mean_ham = final_df['hamming_distance'].mean() if not final_df.empty else 0
print(colored(f"\n✅ Evaluation complete. Processed {processed_images} images.", "green"))
print(f"Results saved to: {FINAL_CSV_PATH}")

print("\n" + "="*50)
print("FINAL RESULTS SUMMARY")
print("="*50)
print(f"Total Records: {len(final_df)}")
print(f"Mean Hamming Distance: {mean_ham:.2f} / 100 bits")
print(f"Results saved to: {FINAL_CSV_PATH}")
print("="*50)

# -*- coding: utf-8 -*-
"""
QPP Attack Evaluation Script (Self-Decoded Control)
Finalized version using nested original data structure and flat attacked data structure.
Compares decoded output of original images with decoded output of attacked images
via Hamming Distance, saving the results to a single CSV.
"""

import os
import numpy as np
import pandas as pd
from PIL import Image, ImageOps
from tqdm import tqdm
import tensorflow as tf
from termcolor import colored

# Suppress TF warnings and disable eager execution
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
tf.compat.v1.disable_eager_execution()

# Path to the nested folders containing image data (e.g., /.../000000/000000_hidden.png)
ORIGINAL_DATA_ROOT = "/content/drive/MyDrive/400x400_test_paired_data"
# Path to the single, flat folder containing all QPP output images (e.g., /.../qpp_outputs/000000_final.png)
QPP_OUTPUT_ROOT = "/content/drive/MyDrive/qpp_outputs_test_nov30"
# Path to the StegaStamp TensorFlow decoder model
TF_MODEL_DIR_ROOT = "/content/drive/MyDrive/stegastamp_pretrained"
# Output directory and final CSV file path
EVAL_CSV_DIR = "/content/drive/MyDrive/hamm_bet_test_original_postprocess"
FINAL_CSV_PATH = os.path.join(EVAL_CSV_DIR, "hamm_bet_qpp_initial.csv")

# Ensure the output directory exists
os.makedirs(EVAL_CSV_DIR, exist_ok=True)

# ============================================================================
# DECODER UTILITY FUNCTIONS
# ============================================================================

def find_model_path(root_path):
    """Checks the root and common subdirectories for the SavedModel files."""
    if os.path.exists(os.path.join(root_path, "saved_model.pb")):
        return root_path
    for subdir in ['1', 'saved_model']:
        test_path = os.path.join(root_path, subdir)
        if os.path.exists(os.path.join(test_path, "saved_model.pb")):
            return test_path
    return root_path # Return root if all checks fail

def load_decoder_handles(model_dir):
    """Load StegaStamp TensorFlow decoder model"""
    g = tf.Graph()
    sess = tf.compat.v1.Session(graph=g)
    meta = tf.compat.v1.saved_model.loader.load(sess, [tf.saved_model.SERVING], model_dir)
    sig = meta.signature_def["serving_default"]
    inp_image = g.get_tensor_by_name(sig.inputs["image"].name)
    inp_secret = g.get_tensor_by_name(sig.inputs["secret"].name)
    out_bits = g.get_tensor_by_name(sig.outputs["decoded"].name)
    return sess, {"image": inp_image, "secret": inp_secret}, out_bits

def preprocess_image_for_decoder(path):
    """Preprocess image for StegaStamp decoder: 400x400, RGB, [0,1]"""
    img = Image.open(path).convert("RGB")
    img = ImageOps.fit(img, (400, 400))
    arr = np.asarray(img).astype(np.float32) / 255.0
    return arr

def decode_bits(sess, inputs_dict, out_tensor, img_path):
    """Decode 100-bit message from image using StegaStamp decoder"""
    if not os.path.isfile(img_path): return None
    img_arr = preprocess_image_for_decoder(img_path)
    dummy_secret = np.zeros((1, 100), dtype=np.float32)
    feed_dict = {
        inputs_dict["image"]: img_arr[np.newaxis, ...],
        inputs_dict["secret"]: dummy_secret
    }
    pred_bits = sess.run(out_tensor, feed_dict=feed_dict)
    pred_bits = np.squeeze(pred_bits).astype(np.int64)
    return pred_bits if pred_bits.size == 100 else None

def compute_hamming(pred_bits, control_bits):
    """Compute Hamming distance (number of differing bits)"""
    if pred_bits is None or control_bits is None: return None
    L = min(len(pred_bits), len(control_bits))
    hamming_dist = int(np.sum(pred_bits[:L] != control_bits[:L]))
    return hamming_dist

# ============================================================================
# MAIN EVALUATION
# ============================================================================

# --- Load StegaStamp Decoder ---
# Attempt to handle potential nested folder structure for robust loading
TF_MODEL_DIR = find_model_path(TF_MODEL_DIR_ROOT)
print(colored(f"Attempting to load StegaStamp decoder from: {TF_MODEL_DIR}", "yellow"))

try:
    sess, inputs_dict, out_bits = load_decoder_handles(TF_MODEL_DIR)
    print(colored("✅ StegaStamp decoder loaded successfully", "green"))
except Exception as e:
    # If this fails, we cannot proceed, but since you said it works, this is a safeguard.
    print(colored(f"❌ Critical Error: Failed to load decoder model. If this persists, verify the contents of your model folder.", "red"))
    exit(1)

# --- Pass 1: Establish Control Keys (P_control) from Nested Folders ---
control_keys = {}
print(colored("\nStarting Pass 1: Decoding Control Keys from Original Watermarked Images...", "yellow"))

# Identify all image IDs by looking at the subfolders in the original data root
all_folders = [d for d in os.listdir(ORIGINAL_DATA_ROOT) if os.path.isdir(os.path.join(ORIGINAL_DATA_ROOT, d)) and not d.startswith('.')]

for image_id in tqdm(all_folders, desc="Pass 1: Decoding Control Keys"):
    # Path format: DATA_ROOT/000000/000000_hidden.png
    original_path = os.path.join(ORIGINAL_DATA_ROOT, image_id, f"{image_id}_hidden.png")

    if os.path.exists(original_path):
        p_control = decode_bits(sess, inputs_dict, out_bits, original_path)

        if p_control is not None:
            control_keys[image_id] = p_control

print(colored(f"✅ Control keys established for {len(control_keys)} images.", "green"))

# --- Pass 2: Evaluate Attacked Images (P_attack) against Control Keys ---
print(colored("\nStarting Pass 2: Evaluating Attacked Images...", "cyan"))

final_records = []
qpp_images = [f for f in os.listdir(QPP_OUTPUT_ROOT) if f.endswith(".png") or f.endswith(".jpg")]
processed_images = 0

for img_file in tqdm(qpp_images, desc="Pass 2: Decoding QPP Outputs"):
    try:
        # Extract image_id (e.g., '000000' from '000000_final.png')
        image_id = img_file.split('_')[0]
    except IndexError:
        continue

    # Get the control key
    p_control = control_keys.get(image_id)
    if p_control is None:
        continue

    qpp_img_path = os.path.join(QPP_OUTPUT_ROOT, img_file)

    # Decode the attacked image (P_attack)
    p_attack = decode_bits(sess, inputs_dict, out_bits, qpp_img_path)

    # Compute Hamming distance: Hamming(P_attack, P_control)
    ham_sd = compute_hamming(p_attack, p_control)

    if ham_sd is not None:
         final_records.append({
            "image_id": image_id,
            "attack_type": "QPP_Self_Decoded",
            "hamming_distance": ham_sd,
        })
         processed_images += 1

# Save the final CSV
final_df = pd.DataFrame(final_records)
final_df.to_csv(FINAL_CSV_PATH, index=False)

# --- Final Console Output (No plots, just required summary) ---
mean_ham = final_df['hamming_distance'].mean() if not final_df.empty else 0
print(colored(f"\n✅ Evaluation complete. Processed {processed_images} images.", "green"))
print(f"Results saved to: {FINAL_CSV_PATH}")

print("\n" + "="*50)
print("FINAL RESULTS SUMMARY")
print("="*50)
print(f"Total Records: {len(final_df)}")
print(f"Mean Hamming Distance: {mean_ham:.2f} / 100 bits")
print(f"Results saved to: {FINAL_CSV_PATH}")
print("="*50)

